{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project we will be analyzing a data set that contains information about posts on the popular site Hacker News. Created by startup incubator Y Combinator, Hacker News is a site where users submit posts which are then upvoted and commented on, similar to Reddit. The data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). \n",
    "\n",
    "For our analysis, we will be interested in two types of posts specifically, Ask HN posts where users submit a question and Show HN posts where users share a project, product or something else of interest. The questions we will look to answer are:\n",
    "- Do Ask HN or Show HN posts receive more comments on average?\n",
    "- Do posts created at a certian time receive more comments on average?\n",
    "\n",
    "Using the answers to these two questions, we will determine what type of post and at what time of day will gain the largest amount of comments.\n",
    "\n",
    "We will begin by reading in our data set and seperating the header row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "hn = list(reader(open('HN_posts_year_to_Sep_26_2016.csv')))\n",
    "header = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(header)\n",
    "print('\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Now that the header of the data set has been removed, its time to clean up and filter our data prior to analysis. As stated before, we are only interested in Ask HN and Show HN posts so our next step will be to extract those posts from our data set. We will create three new subsets of the data, one containing only Ask HN posts, one containing only Show HN posts, and the third will contain all other posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN Posts:  9139\n",
      "Show HN Posts:  10158\n",
      "Other Posts:  273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Ask HN Posts: ', len(ask_posts))\n",
    "print('Show HN Posts: ', len(show_posts))\n",
    "print('Other Posts: ', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Next we will use our new data subsets to answer our first question, do Ask HN or Show HN posts receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Number of Comments for Ask HN Posts\n",
    "\n",
    "First we calucate the average number of comments for Ask HN Posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Comments for Ask HN Posts:  10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print('Average Number of Comments for Ask HN Posts: ', avg_ask_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Number of Comments for Show HN Posts\n",
    "\n",
    "Now we will repeat our calculation for Show HN posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Comments for Show HN Posts:  4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print('Average Number of Comments for Show HN Posts: ', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our analysis we can see that on average, Ask HN posts receive around twice as many comment than Show HN posts. Since we now know that Ask HN posts receive more comments, we will continue our analysis by focusing on these posts. The next question we will answer what is the best time of day to post an Ask HN post in order to generate the highest amount of comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Amout of Ask HN Posts and Comments by Hour Created\n",
    "\n",
    "We will now work to determine the hour of the day that the most Ask HN posts are submitted and the hour that the most comments on Ask HN posts are generated. To accomplish this we will work with the Python datetime module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "4234\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    # Extract post creation time and number of comments\n",
    "    result_list.append([post[6], int(post[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for result in result_list:\n",
    "    date = result[0]\n",
    "    dt_object = dt.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    hour = dt_object.strftime('%H')\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = result[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += result[1]\n",
    "        \n",
    "print(counts_by_hour['12'])\n",
    "print(comments_by_hour['12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use our `counts_by_hour` and `comments_by_hour` dictionaries to calculate the average number of comments per post for every hour of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, (comments_by_hour[hour] / counts_by_hour[hour])])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our data, but we will quickly reformat to make it easier to interpret:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask HN Post Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n",
      "04:00: 9.71 average comments per post\n",
      "14:00: 9.69 average comments per post\n",
      "17:00: 9.45 average comments per post\n",
      "08:00: 9.19 average comments per post\n",
      "11:00: 8.96 average comments per post\n",
      "22:00: 8.80 average comments per post\n",
      "05:00: 8.79 average comments per post\n",
      "20:00: 8.75 average comments per post\n",
      "21:00: 8.69 average comments per post\n",
      "03:00: 7.95 average comments per post\n",
      "18:00: 7.94 average comments per post\n",
      "16:00: 7.71 average comments per post\n",
      "00:00: 7.56 average comments per post\n",
      "01:00: 7.41 average comments per post\n",
      "19:00: 7.16 average comments per post\n",
      "07:00: 7.01 average comments per post\n",
      "06:00: 6.78 average comments per post\n",
      "23:00: 6.70 average comments per post\n",
      "09:00: 6.65 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hour[1], hour[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print('Top 5 Hours for Ask HN Post Comments')\n",
    "\n",
    "for item in sorted_swap:\n",
    "    hour = dt.datetime.strptime(item[1], '%H').strftime('%H:%M')\n",
    "    print('{}: {:.2f} average comments per post'.format(hour, item[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conculsion \n",
    "\n",
    "Looking at our final analysis, it is clear that the best time of the day to generate comments on an Ask HN post is 15:00 (3PM). Ask HN posts created at 15:00 generate an average of almost 29 comments, nearly double of the next most popular hour 13:00 which generates around 16 comments on average. Overall, our data shows that a good time of day to create Ask HN posts is the afternoon, as the highest 3 comment generating hour are 12pm, 1pm, and 3pm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
